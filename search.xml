<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SMP CUP 2018]]></title>
    <url>%2F2018%2F07%2F12%2FSMP-CUP-2018%2F</url>
    <content type="text"><![CDATA[时间太快啦，转眼就一年了，又到了SMP CUP 2018的时候。今年比赛和去年略有不同，去年是一份数据三个任务，今年则是一个任务独享一份数据。任务一文本分类，任务三文本溯源。 比赛简介 任务一文本分类：给定一篇短文，判断是人类作者、自动摘要、机器翻译和机器作者中的哪一种，详见官网 任务三文本溯源：给定一个句子，判断是否复制或改编(删减/摘要/替换/重排等)于其它的句子，详见官网 数据样例 任务一：ID12345 ||| 方法通过文献研究、药物实测、炮制方法、方药配伍、煎服方法、安全性及临床用药特点等方面考证《伤寒论》药物剂量。 任务三：自动摘要 ||| 自动摘要生成的文章，从新闻网站爬取后调用各种自动摘要工具生成，共60,000篇。 思路总结 任务一：基础文本分类模型如TextCNN、TextRNN和Fasttext等分别训练，然后模型融合。 任务三：句子相似度计算，然后对召回句子进行优化排序。这里要注意的是，任务三中没有任何的标签，因此是一个无监督的候选句子排序任务。考虑到句子间循环匹配的数量级，我搭建了ElasticSearch全文检索引擎来帮助初选优化，大大降低了检索成本。 模型实现 我在github上的开源代码 比赛心得 任务一： 1.基础模型没能做到极致，仅仅尝试了TextCNN和Fasttext； 2.计算资源要充足，没能把TextRNN做起来的原因有一部分就是实验室的服务器没有GPU…； 3.时间要安排好，工作要分配好，临近毕业实在是太忙了… 任务三： 1.想到用ES来加速查询真的是个非常正确的决定，因为测试集计算量是验证集的200倍; 2.最后实现的还是句子匹配，而非文本理解和溯源。没想到很好的方法。 总的来说，写代码比去年顺手多了，也规范很多。比赛套路也熟悉了很多，从容了一些。但是真的要到进一步提升效果，冲刺排名的时候，就会因为平时积累不够而有心无力。比如说模型融合应该是要基于差异性大的底层模型，这一点我也是在整个比赛结束时才深有体会。再比如Attention和LSTM相关的网络都没能写完、运算完，师哥说的Fasttext能有0.976的结果也没有实现，这些都是因为平时没有去实现过。所以未来还是要好好加油啊！]]></content>
      <tags>
        <tag>Data Mining Contest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SMP CUP 2017]]></title>
    <url>%2F2017%2F08%2F31%2FSMP-CUP-2017%2F</url>
    <content type="text"><![CDATA[SMP CUP 2017是我参加的第一个数据挖掘类比赛。 比赛简介给定CSDN用户的博客和行为数据（浏览、评论、收藏、转发、点赞/踩、关注、私信），进行用户画像生成。赛事官网地址：https://biendata.com/competition/smpcup2017/画像生成总共分为三项任务： 从给定博文中抽取3个关键词标签 从给定标签空间中选出3个来给给定用户打标签，依据是用户发表的博文以及一系列行为数据 通过给定用户过去一段时间的行为数据，预测其在未来一段时间内的成长值。用户成长值是根据用户的综合表现打分所得，但不知道具体打分准则。成长值将会归一化到[0, 1]区间，其中值为0表示用户流失。 数据样例 项目 内容 用户ID U00296783 博文ID D00034623 博文内容 Title:[转]使用TextRank算法为文本生成关键字和摘要; Content: TextRank算法基于PageRank… 博文标签 Keyword1: TextRank; Keyword2: PageRank; Keyword3: 摘要 用户标签 Tag1: 大数据; Tag2: 数据挖掘; Tag3: 机器学习 发布记录 U00296783／D00034623／20160408 12:35:49 浏览记录 D09983742／20160410 08:30:40 评论记录 D09983742／20160410 08:49:02 点赞记录 D00234899／20160410 09:40:24 点踩记录 D00098183／20160501 15:11:00 私信记录 U00296783／U02748273／20160501 15:30:36 收藏记录 D00234899／20160410 09:40:44 关注记录 U00296783／U02666623／20161119 10:30:44 成长打分 0.0367 (注：浏览、评论、点赞、点踩和收藏指的是该用户对其它博文的行为) 思路总结 抽取关键词其实方法也不太多，一开始想到的办法就是利用tfidf和textrank。后来查阅到了一些2016年搜狗CCF比赛的资料，就尝试把LDA抽取出来的主题关键词作为规则融合进来。简而言之，就是不断调整tfidf和textrank赋予给每个词的权重，尽可能地去提升比赛评分标准下的得分。 任务二大概的做法是先把用户行为分类转化成对应的文章，发表行为下的文章是一类，浏览的、评论的、点赞点踩的、收藏的文章是一类，私信和关注的用户所写的文章是一类。这个假设非常的主观，我们当时的依据就是用户做这些行为的成本不一样，比如说发表文章比较累…所以这些文章可以被分成3类，刚好对应3个标签(其实简单对训练集做了统计发现这个规律也确实还有一点点道理)。之后就是让每一类文章投票选出一个最可能的标签，分类方法是tfidf加权生成句向量+SVC。 成长值这个任务其实一看就是和时间序列有关的，但是局限于代码水平…当时就直接当作一个简单的回归问题来处理。先手动抽取了一些特征，比如每个用户过去每个月的评论数及增长率等，然后直接丢到PassiveAggressive和GrandientBoosting分类器里面，加一个Stacking做了融合预测。 模型实现 我在github上的开源代码 比赛心得 任务1：现在回过头来看这个方法真的非常稚嫩，但是倒也相当符合“规则派”的做法，毕竟我后来的实习工作中也证明了规则的有效性。不过第一名中科院团队的做法是纯正的神经网络，用来多个Softmax来投票，效果比第二名好了一大截，我怀疑除了他们大家都是tfidf+规则… 任务2：最开始采用了TextCNN的方法，但是效果比较一般，主要是不知道怎么把单标签分类的模型改成多标签…现在想想其实就是一个SoftMax…任务2我们的效果是最差的，我猜测就是因为主观假设太强了。 任务3：说实话这个模型的效果竟然意外的好，我觉得应该是因为纯数字数据的原因，毕竟对于数字，机器还是很容易去“拟合”一个模型出来的。 不过总的来说，当时真的是年轻头铁硬扛…开始比赛前，我连sklearn和numpy这些必备的包都不会用，更别说tensorflow和keras了。当时也是运气好，比赛因故延期了很长时间，我在比赛中期发现了kaggle和泰坦尼克数据集，并且由此自学了一堆机器学习的东西，才最后踉踉跄跄搞出了任务3的模型。像时间序列预测等等都没法做出来，很重要的原因是花了很长时间自学这些底层的东西，虽然按理来说应该在赛前就先打好基础的。不过回头看，此前整个实验组都没有经验，因为我们的辛苦帮老师和实验组做了一些开拓性的事情，还是非常让人喜悦的。]]></content>
      <tags>
        <tag>Data Mining Contest</tag>
      </tags>
  </entry>
</search>
