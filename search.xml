<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SMP CUP 2018]]></title>
    <url>%2F2018%2F07%2F12%2FSMP-CUP-2018%2F</url>
    <content type="text"><![CDATA[时间太快啦，转眼就一年了，又到了SMP CUP 2018的时候。今年比赛和去年略有不同，去年是一份数据三个任务，今年则是一个任务独享一份数据。任务一文本分类，任务三文本溯源。 比赛简介 任务一文本分类：给定一篇短文，判断是人类作者、自动摘要、机器翻译和机器作者中的哪一种，详见官网 任务三文本溯源：给定一个句子，判断是否复制或改编(删减/摘要/替换/重排等)于其它的句子，详见官网 数据样例 任务一：ID12345 ||| 方法通过文献研究、药物实测、炮制方法、方药配伍、煎服方法、安全性及临床用药特点等方面考证《伤寒论》药物剂量。 任务三：自动摘要 ||| 自动摘要生成的文章，从新闻网站爬取后调用各种自动摘要工具生成，共60,000篇。 思路总结 任务一：基础文本分类模型如TextCNN、TextRNN和Fasttext等分别训练，然后模型融合。 任务三：句子相似度计算，然后对召回句子进行优化排序。这里要注意的是，任务三中没有任何的标签，因此是一个无监督的候选句子排序任务。考虑到句子间循环匹配的数量级，我搭建了ElasticSearch全文检索引擎来帮助初选优化，大大降低了检索成本。 模型实现 我在github上的开源代码 比赛心得 任务一： 1.基础模型没能做到极致，仅仅尝试了TextCNN和Fasttext； 2.计算资源要充足，没能把TextRNN做起来的原因有一部分就是实验室的服务器没有GPU…； 3.时间要安排好，工作要分配好，临近毕业实在是太忙了… 任务三： 1.想到用ES来加速查询真的是个非常正确的决定，因为测试集计算量是验证集的200倍; 2.最后实现的还是句子匹配，而非文本理解和溯源。没想到很好的方法。 总的来说，写代码比去年顺手多了，也规范很多。比赛套路也熟悉了很多，从容了一些。但是真的要到进一步提升效果，冲刺排名的时候，就会因为平时积累不够而有心无力。比如说模型融合应该是要基于差异性大的底层模型，这一点我也是在整个比赛结束时才深有体会。再比如Attention和LSTM相关的网络都没能写完、运算完，师哥说的Fasttext能有0.976的结果也没有实现，这些都是因为平时没有去实现过。所以未来还是要好好加油啊！]]></content>
      <tags>
        <tag>Data Mining Contest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP Internship in Ideepwise Infotech]]></title>
    <url>%2F2018%2F06%2F13%2FNLP-Internship-in-Ideepwise-Infotech%2F</url>
    <content type="text"><![CDATA[2018年3月-2018年6月，我在深思考自然语言处理组担任算法实习工程师 求职面试 是人生中的第二份面试啦，一定程度上算是“老司机”了。 面试分成笔试、上机、技术一面、技术二面、技术三面和HR面。 笔试 有一道概率题，贝叶斯公式带入算一下就可以。 有一道算法题，考的是排序优化，我做出来了，但是方法并不是最好的。 比较奇怪的是，其它几乎都是概念和问答题，机器学习与自然语言处理相关，都不是特别难。 上机 这个算是比较有特色的环节了。 现场要求做一个上机题，关于字符串匹配的，就是要求比较复杂，比如去掉含A的、保留含A但含B的、保留含A但含C且长度小于5的等等，难度不大。不过上机环境是台式机，我不太习惯，还好我习惯去面试带着自己的电脑(首要目的是问到以前工作可以展示代码或界面)。 技术面 一面基本上围绕笔试题，这一次由于有第一次实习的基础，加上我寒假刷了一些leetcode，所以做得还行(其实主要是这次笔试简单了)。 二面主要是白板写算法。印象最深的是问了一个位运算的题：把一个十进制数转换成二进制以后，计算这个二进制数中有多少个1。我用的是最简单的短除法，实现的时候每次减去2的幂就可以了。相比之前的面试，我的进步在于可以白板直接写出来程序了，而缺点还是没有给出最优的方案。算法永无止境，我还需要努力。 三面问了一些实际开发的内容，主要就介绍了SMP CUP 2017(主要是这家公司也参加过这个比赛，虽然不是同一个Track的任务)，以及上一份实习构建问答系统的工作。这里可以插一句，我带电脑真的有用，直接展示了问答系统的前端demo，说服力就很强了(不过很尴尬的是，调用在线搜索后，百度居然直接给了我一个带有色情信息的回答…当时我的脸和面试官一起绿了…还好我机智地说这是即将改进的部分…)。 工作 2018.3：自动问答机器人，主要是套用之前实习开发的系统框架+新公司数据+针对性调整。说实话我觉得这个新公司招我进来重要的原因就是偷学技术…所以在这个过程中我特别注意了数据和参数脱敏的问题，保证保密性(不能违背保密合同)。 2018.4：百度机器阅读理解比赛。尽管我在比赛中实现的实际成果不多，但这份工作经历对我来说比较重要，因为我第一次比较系统地去深入调研和理解了自然语言处理中的某一任务专题，以至于我最终的毕业设计也聚焦在机器阅读理解这项任务上。相关代码和工程还在完善中，之后应该也会开源到我的GitHub上。 2018.5：孪生网络句对相似度计算模型，这份工作来的有点突然，毕竟我本来还是在专心研究机器阅读理解的…目前成果一般，后续可能还会有深入研究，不过它也促进了我对目前自然语言处理领域工作的理解。 感想自然语言处理的核心工作是什么？ 在应用研究层面，应当是文本建模。文本建模意味着什么？意味着通过文本数字化，机器“读懂”了文本。只有理解了文本，机器才能开展文本分类、生成、问答、翻译和阅读理解等工作；只有数字化后的文本能更全面、充分和尽可能少损失地被表示，机器的“智能”才能提升，才更可能拟人。当然，除此以外，能对自然语言处理的研究产生巨大影响的还有文本向量化、模型网络类脑化等工作。只不过它们都不太好上手，文本建模应当是普及最广、被研究最多和进展最快的一类研究。 就我个人观察，文本建模已经从加权tfidf、双向lstm和cnn等方法逐渐往自注意力机制和优化卷积等方法变迁，其中引领潮流的当然是Google著名的《Attention is all your need》一文。在机器翻译和机器阅读理解领域，代表性的新新模型当属Transformer和QANet。 工程和算法的区别？ 在百分点，我更多的是从基础做起，做工程、做产品。五个月里，我锻炼了写代码的能力、熟悉了团队工作环境，知道怎么用wiki、git、filezilla和linux等等一系列东西，可以说是从0到1。 在深思考，我则尝试着去思考自己想做什么，在一定程度突破了代码障碍的基础上，开始学会读论文、追前沿和做模型。算法相比工程最大的区别，就是不必再因为客户的具体需求而去调试参数和设定人工规则，而可以专注于模型本身的设计，去思考学术研究上的优化。我觉得我被这种开创性的研究工作深深吸引着。 换实习要不要“裸辞”？ 原则上不要，因为裸辞会产生空窗期。在空窗期，公司一般不在意我们在学校实验室里做了什么，甚至会认为只是在休息(也就意味着代码实践能力在下滑)。 不足 实习时间太短，没能做更多研究。 公司加班太多(虽然我几乎都没有参与)，我认为被动加班太多只会引起效率下降，劳逸结合、平衡工作和休息才是正道。]]></content>
      <tags>
        <tag>Internship</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Postgraduate Application]]></title>
    <url>%2F2018%2F05%2F31%2FPostgraduate-Application%2F</url>
    <content type="text"><![CDATA[2017年10月-2018年6月，伴随着长达8个月的实习，我度过了漫长而揪心的研究生申请季。我的背景是双非一本信管，GPA90，T101，G160+170+3.5。我申请的方向是CS/DS，最后结果是申11中3，一所平调，一所降调带奖，一所带奖。我是全程自己DIY，没有找中介。 准备学历背景 如果还有的选，一定去一所综合性211/985，尽可能不要去那种“分数并不低于985，所以学校也不差于985”的院校(比如我…)，或者那种“小规模精英办学”的院校(又比如我…)。原因在于：1.外国录取委员会更相信中国政府给出的大学档次排名，而不相信我们自己在文书中对学校品质的努力解释；2.小平台=小资源=小校友圈子=少出国人数=少在录取委员会眼前曝光，同时小资源=少有分量推荐信，小资源=少机会提升自己的软实力。 学历背景是很硬的基础。英国规定的最明确，211/985的同学录取GPA要求比双非一本低5分；美国则是隐性要求，不过这一要求没有那么5分那么多，但3-4分左右是要的。 在这一点，对于我个人，我的办法是去读了北大经双(北京高校同学都可以考)。虽然因为我申请的方向和经济/金融关系很小，帮助不大，但是在我找实习、认识更多学校的优秀同龄人、找推荐信等方面都起过或多或少的作用。 语言考试 语言考试指的是托福、雅思、GRE和GMAT等。我考的是托福和GRE。 托福：我从大二开始断断续续考托福，直到大三暑假才考完，前前后后加起来大半年。因为自己的英语基础确实不好，再加上没有很大块的时间可以专心备考，所以战线只能拉的很长。托福我的总结就是多练，刷阅读刷听力刷口语刷写作。以我的经验，从85到101分大概需要100小时全神贯注的学习(一般来说自习一整天=2小时全神贯注)。 GRE：GRE我确实很占便宜，因为我的强项恰好是阅读。所以尽管GRE我也是断断续续准备，但是因为只需要准备单词部分，就比较轻松。我的GRE是在大三下及八月准备的(中间穿插考了一次托福)，阅读从155进步到160。我对GRE的认识是，这门考试考的是短时间大量练习的消化能力，考前反复背10天单词做50篇阅读和10篇作文，考的时候效果很显著。 GPA 我的GPA其实还不错，虽然用我们学校的绩点计算只有3.65。 网上有很多计算绩点的方法，众说纷纭。其实最好的办法就是直接报百分制GPA，这种制度全世界认可，并且还能用99/98来挽救一下非线性下降的绩点。 还有一种办法是把成绩送去WES认证，这个机构出具的成绩报告是比较有效力的，并且对于中国学生一般会使绩点提高一些。但它认证时间较长且贵(几千RMB)，请自行慎重决定。 推荐信 推荐信不太重要，因为你很难让它很重要。如果能找到蜚声国际的人写推荐信，那么推荐信几乎等于保送。比如我校曾有师哥拿到海牙国际法庭大法官推荐信，直接去了哈佛法学院。 对于一般人来说，推荐信都是学校教授和实习公司领导写。建议学校教授找国际知名度高一些的和对自己非常了解的(上过很多门课的)，实习公司领导则要尽可能去大名气的公司找高级别领导。 中国人的推荐信可以说是国际默认自己写的，这里提示一些推荐信要点：1.扫描一张带有机构title的纸作为pdf文件的背景；2.要一个推荐人的电子签名；3.推荐信不宜过长，要有详有略，末尾写上推荐日期和电子签名；4.和推荐人协商好，把含有所有学校的推荐信提交链接的邮件及时转发给自己；5.提交推荐信的时候可以开VPN来避免ip查重。 这里可以延伸说一下实习，我犯的错误是太忽视公司名气。确实，在公司做了什么项目、学到了什么最重要，但是公司名气同样重要，因为很多录取委员会的人只听说过国际大公司，一个小公司的核心成员的名头很难说服他们。 确定学校及项目 在整个申请中，最重要的是确定学校和想学的项目。 粗选：先确定底线，比如QA排名Top50，然后挨个打开官网搜自己想学方向的关键词(比如传媒=communication、media和advertising等)，把所有搜到的项目页面打开，浏览一遍项目培养目标、课程设置和录取要求。再根据自己的实力(上述四点)，筛选一遍候选项目。 精选：看候选项目的录取细节，要不要准备特殊材料、是不是只给有工作经验的人读，以及学生毕业去向、往年录取比例等等(练T&amp;G阅读终于有了用武之地233)。最终建议锁定大概10-15个项目。 文书 首先根据学校要求，确定有哪些：Personal Statement、Statement of Purpose、Research Proposal、Essay、Essay Video、Resume等等。 根据每个文书下面的具体要求，按学校要求写作(划重点)。这里特别要注意去看项目页面上的FAQs，很多都会有文书材料内必须包含内容的要求，一定要把这些基本要求达到。 文书的写作我建议先按照中文思路，总分总(为啥申请/你的优势123/未来计划)。把每一块儿写清楚了以后，再按照西式思路调整，比如开头用一个引人入胜的小故事、结尾用个自己对这个行业和社会的思考等等，使之文学化、情感化。另外要注意文书重点是体现个人的潜力，不是现有的成就，毕竟录取委员会的人很可能不是特别懂专业上的事。 实在把握不准，可以找文书中介。 网申提前办Visa或Master卡 网申是需要用信用卡的，需要提早办理，以便网申的时候不慌乱。 注意各种deadlines 看项目主页的时候，里面会有申请项目的开放申请和具体截止时间。有的申请是滚动录取的，会明确写上一批二批三批等申请和录取时间点，需要额外注意。其次是要分清国际生和本地生、研究生和博士生的时间界线，一般来说国际生截止日期早于本地生，博士生早于研究生。 准备各种材料 一是明确的邮寄地址、不会失效的电子邮件地址、推荐信作者的联系信息等电子材料。 二是护照扫描件、本科中英文成绩单和在读证明扫描件、获奖证书扫描件、TG成绩单扫描件等实体材料转电子版。 三是在ETS官网购买TG送分服务、WES成绩认证送分服务等电子事务，这些都需要用信用卡支付。 提交及等待 提交完网申以后，注意看看哪些信息还可以继续更新，有的学校还允许继续更新语言成绩(意味着还可以再刷)。 漫长的等待，以及随时注意邮箱(和垃圾邮箱)中学校发来的邮件，看是否有材料需要补充。 如果被调剂了(被该项目拒了，但是推荐了别的项目)，想申请的话就要立刻赶快再填写网申，抢人头。 入学确认Offer(无奖录取=admission，有奖录取=offer，这里用offer统称) 正常的offer发放日期应该是大四寒假及大四下。在比较多家offer后，给最心仪的学校交订金，其它的写信礼貌拒绝。 对确认好的offer尽早开始研究细节，特别重要的是申请I-20表格，这一点对于后面申请签证、体检疫苗和租房等都有影响。一切信息以官网为主，一般会有一个admitted student页面来说明所有事务。 项目细节 很多项目会为被录取者开一个网上研讨会Webinar，来介绍今年项目的各种细节，包括课程设置、教学日历、就业升学、校友资源和学校资源等。这是一个很好的去了解该不该接offer的机会。 签证 务必重视材料的准备！！！ 需要的材料有：1.学校I-20表格；2.个人resume；3.学术型项目需要提供的导师简历；4.DS-160打印页、预约确认单和美签尺寸的照片等使馆要求的必备物品；5.学习计划 面签时要尽早去排队。我是在北京约的7:30到使馆，然而7:10到的时候已经排起了长龙；不过整个流程不算慢，约1小时。 其它细节：1.照片要求比较复杂，深色衬衣和白背景，建议找天真蓝这类机构进行拍摄；2.北京使馆对面是可以存东西的（面签时不能带手机），然而我当时交给街头小贩保管了…损失了100大洋；3.最好找白人男签证官。我分到了全北京拒签率最高的那位亚裔女签证官，然后就GG了…补了很多材料，这几天才通过。 补签：如果被发到221绿表，也不用太紧张，多半是要以邮件形式补充材料。行政审理期大概1周到4周不等，如果当场不留护照的话，最后还得通过中信银行寄送护照回使馆去盖签证（免费寄送）。 体检/疫苗 体检是为了拿到健康证明小红本。疫苗是为了拿到疫苗证明小黄本，同时可能需要完成学校规定的疫苗注射，并请医生填写学校的外文单。 体检/疫苗攻略：https://mp.weixin.qq.com/s/S8FOFCJINn-5v7E-qq1TXg 温馨提示：大城市如北京，一般疫苗种类齐全，但排队人数众多，还需要提前预约；小城市可能疫苗种类不足，需要提取打电话问一下，但是胜在完全没人排队，半小时即可全部搞定。我就是疫苗在北京打，但体检回自家小城市做的。 机票/租房/家具 机票：1.至少提早一个月买，便宜点；2.在第三方平台看好机票后，去该航空的官网买可能会更便宜一点；3.去美国的话飞行时间特别长，建议能买评分高的航空就买高的，舒服一些。比如ANA、卡塔尔航空、南航等等；4.不买直航买转机的话，建议两段旅程都不要飞太久，比如…从香港转就有一段16～17个小时，会累死的= =。 租房：讲道理可以不找中介自己租，但是纽约租房可能是全美最复杂的租房了，所以还是找了在做中介的NYU学长帮忙。有几点tips：1.尽早租房，晚了就没好房源；2.尽早找好合租的人，然后大家按实际使用面积分摊房租，最好在敲定房子前就分配好比例；3.合同签署后48小时内就得付押金等，所以要先准备好一些钱；4.纽约还有一点特殊的就是部分新房需要有当地第三方机构担保，所以还要准备更多的押金… 家具：一般来说新生老生们会拉二手家具交易群，可以随时关注里面的信息。如果不想买二手的，就去亚马逊上买，但是记得地址一定要填到公寓的详细单元号，否则会寄丢(譬如我…)！！！ 感想 最大问题就是学历背景。师哥曾和我说，双非申学校，如果没有比同样申这个学校的985同学各方面都好上一截儿，就别考虑了。现实很残酷，我的申请结果也证明了这一点。 其次问题是太轻视托福。当时老看网上说托福过百即可，所以就没有继续认真刷。但事实上，105+的托福能让一个人从一群100+的申请者中脱颖而出。此外，GRE的重要性远低于托福，G320+T110&gt;&gt;G330+T100。 有好几个项目是我心有不甘的，当时看了地里被录取的人的背景，基本和我一致，唯一区别就是学历和一些软经历。所以说如果当时自己把托福考得更高一点、实习找的名气(比如几乎保送北美top10的msra)再大一些，也许结果就又完全不同了。 第一次有一段很长时间的半夜惊醒去查看邮箱，第一次因为失去信心匆匆忙忙追加保底院校，但也是第一次自己认认真真做完人生的一件大事。不能后悔，不必后悔，也更想感谢一路帮我的朋友们！]]></content>
      <tags>
        <tag>Postgraduate Application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Siamese-LSTM (孪生网络)]]></title>
    <url>%2F2018%2F05%2F03%2FSiamese-LSTM-%E5%AD%AA%E7%94%9F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[最近因为公司leader的要求，简单研究了一下孪生网络(Siamese LSTM，一个用来计算句对相似度的模型)。 背景 孪生网络的思想比较简单，是分别利用LSTM对待比较的句对中句子进行建模，然后计算两个隐层向量的曼哈顿距离(Manhattan distance)来评价句子相似度。由于LSTM建模过程一致，因此可以用全部句子训练LSTM的参数，然后参数共享给左右两个LSTM网络。 要点 1.将句子建模网络从LSTM改造为Bi-LSTM+Attention 2.中文训练数据为蚂蚁金服句对数据，约4万组，正负样本比例1:3.6；英文训练数据来自Kaggle上的Quora句对数据，约40万组，比例1:1.7。翻译数据指使用Google Translator将Quora数据翻译成中文(机翻，质量一般)。 资料 参考文献 Siamese Recurrent Architectures for Learning Sentence Similarity How to predict Quora Question Pairs using Siamese Manhattan LSTM 其它数据 英文词向量：GoogleNews-vectors-negative300.bin.gz 英文词向量：GoogleNews-vectors-negative300.bin.gz的百度网盘地址 中文词向量：基于120G中文语料训练的64维、128维词向量 工程参考 likejazz/Siamese-LSTM Original author’s GitHub 做个聊天机器人/智能客服 一些网络设计思路 代码 我的实现 结果123456789$ 根据数据比例来看，中文训练集的基准准确率应为0.783，英文与翻译数据为0.630$ =================================================================================================$ 中文 数据实际训练 5 轮时的效果：使用随机词向量时，训练集十折交叉0.778；使用CN120G词向量时，训练集十折交叉0.789$ 英文 数据实际训练 5 轮时的效果：使用随机词向量时，训练集十折交叉0.774；使用Google词向量时，训练集十折交叉0.771$ 翻译 数据实际训练 5 轮时的效果：使用随机词向量时，训练集十折交叉0.755；使用CN120G词向量时，训练集十折交叉0.756$ =================================================================================================$ 中文 数据实际训练 8 轮时的效果：使用随机词向量时，训练集十折交叉0.777；使用CN120G词向量时，训练集十折交叉0.787$ 英文 数据实际训练 8 轮时的效果：使用随机词向量时，训练集十折交叉0.774；使用Google词向量时，训练集十折交叉0.778$ 翻译 数据实际训练 8 轮时的效果：使用随机词向量时，训练集十折交叉0.786；使用CN120G词向量时，训练集十折交叉0.786 总结 1.有无预训练词向量几乎不影响结果。 2.中文数据上训练几乎没有效果，和英文形成鲜明对比–这是因为蚂蚁金服数据间太相似了或者数据量太小，翻译数据集上的实验证明了这一点。 3.孪生网络的效果没有想象中的那么好，后续还会继续从调参、加停用词等角度进行研究。此外，之前在QA机器人中用CNN来做句子语义匹配时缺少数据，现在这里的数据可以用了！233]]></content>
      <tags>
        <tag>SentenceMatching</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My QA Robot]]></title>
    <url>%2F2018%2F04%2F01%2FMy-QA-Robot%2F</url>
    <content type="text"><![CDATA[从2017年10月-2018年3月，出于实习公司的要求，我尝试搭建了一个简单的单轮检索式问答系统。 背景 目前，自动问答技术的实现主要有阅读式、检索式和生成式三大类。 阅读式：指机器阅读理解，通过给定文章和针对文章提出的具体问答对训练机器的阅读理解能力，并对针对文章的新问题作出回答。机器阅读理解包括passage-based、assertion-based、sentence-based和answer-span-based等不同粒度。阅读式的问题是知识边界狭窄，训练语料构筑困难，较适合于专业领域的机器人。 生成式：指使用Seq2Seq搭配海量语料训练具有自主对话能力的系统。生成式理论上可实现不受知识局限的通用机器人，但目前生成式最大的问题是答非所问、胡言乱语，无法表现出人类在解决问题时的逻辑自洽、思维发散和自然表达等能力。这个实现技术比较多用在闲聊机器人方面。 检索式：检索式是一种取长补短的中间无监督技术。检索式要求搜集众多在线问答网站海量的历史问答对语料作为知识库，通过检索与新问题最接近的历史相似问题和最匹配这一新问题的历史最佳问答，变相完成自动问答任务。检索技术既避免了知识的局限，又利用了人类的先验经验积累，是当前处理通用问答任务较合适的方法之一。 思路 结合实际，我的设计为：1.通过爬虫和用户历史数据建立QA式本地知识库；2.当给定用户新问题时，系统先通过ES（ElasticSearch，ES原理）进行词义级的本地检索得到参考问答初选集；3.使用语义深度匹配和问答质量评估从初选集中精选出参考问答精选集，按得分降序返回最终参考问答；4.若没有任何问答通过精选，则启动在线搜索获取标识有“最佳问答”的参考问答返回给用户，并将其中的优质问答缓存到本地ES索引中。 变量或参数名 说明 StopWords 停用词表 KeyWords 核心主题词表 Text_Main_Content(TMC) 用户新问题经分词、去除停用词后的分词结果 Keywords_in_Content(KIC) 用户新问题命中的核心主题词 Text_NER_List(TNL) 用户新问题中的分词后的NER Question_Main_Content(QMC) ES本地检索返回的候选问题经分词、去除停用词后的分词结果 QuestionScore(QS) 语义匹配模块返回的候选问题与新问题的相似度得分 AnswerScore(AS) 通过答案排序模块计算出的，候选问题对应的候选答案与用户新问题组成“好问答对”的概率得分 FinalScore(FS) 候选问答在精选规则下的最终得分 THRESHOLD 控制在精选集中记录ES初选结果的阈值。 ZHIDAOMAX 控制在线搜索时从百度知道返回的问答数量。 SAVESCORE 控制增量存储模块中的百度知道问答对的阈值 ESMAX 控制精选集中的精选问答数量 子模块 根据上文项目思路的介绍，除主函数外，共调用了语义深度匹配、问答质量评估和在线搜索缓存三大子模块 语义深度匹配子模块：参考项目 句对预处理及建模: 将输入的句子1与句子2进行分词，然后将两组切分后的结果两两计算基于Word Embedding的余弦相似度，并填充成上图所示的2D Feature Map形式。当句对的分词list长度不同时，使用0填充缺失值。 模型训练与调用：训练时，将训练集句对的Feature Map输入到CNN模型中，获取语义匹配模型并保存；预测时，调用预训练好的语义匹配模型，输入新句对的Feature Map，将返回这组句对的相似概率得分。 问答质量评估子模块：使用若干文本和非文本特征训练二分类器，参考论文 在线搜索缓存子模块： 百度主页搜索: 向百度主页请求输入用户新问题后的检索结果，若检索结果的第一条中包含预设结果链接，则获取内容并向用户返回。 百度知道搜索：当百度主页搜索没有结果时，在百度知道页面请求输入用户新问题后的检索结果，若Top K条结果中包含带有“最佳回答”标识的回答，则获取对应问答内容并返回。 本地缓存优质问答：当百度知道搜索有结果返回时，调用问答质量评价子模块对该问答对进行质量判断，将高于设定阈值(SAVESCORE)的问答对缓存到本地知识库。缓存机制有助于后续提升系统整体的响应速度及性能。 代码 My QA Robot 总结 项目内：1.项目执行时，语义深度匹配子模块缺少合适的负样本(词义上相似但语义不相似的句对)；2.各种参数阈值很难调试。 项目外：工程性太重，并且以检索为主，在语义理解、匹配和推理方面展开太少。]]></content>
      <tags>
        <tag>QuestionAnswering</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Assertion-based QA with Question-Aware Open Information Extraction]]></title>
    <url>%2F2018%2F03%2F26%2FAssertion-based-QA-with-Question-Aware-Open-Information-Extraction%2F</url>
    <content type="text"><![CDATA[实验室组会分到一篇断言式QA的论文，阅读后总结如下 背景AAAI 2018 要点 1.定义了基于断言的QA任务(Assertion-based QA) 2.标注了一个Assertion-based QA数据集 3.提出了能够完成Assertion-based QA的两个算法，抽取法和生成法 4.设计了一些实验证明以上方法的效力 内容定义 文章首先介绍了从document_based QA和Assertion_based QA的区别与联系。 文章中的断言指的是具有主谓宾、主谓宾补等结构的句子，该句子可能是给定材料的一部分，也可能是新生成的。 数据集 由于Assertion-based QA是第一次被提出，所以作者团队标注了一个数据集来做具体的研究(666)。 标注方法是先用OIE工具+is-a规则从背景材料中抽取候选断言，然后人工标注断言是否可以作为答案。 算法 第一种算法是生成法。首先用bi-lstm分别对问题和材料编码，拼接尾部隐状态作为特征表示。其次先用一个元组级解码器(Tuple-level decoder)生成结构，然后再用词级别解码器(Word-level Decoder)在结构中逐个生成需要填充的词。下图来自PPT，但是缺了不少信息，我做了批注。 第二种算法是抽取法。抽取法的本质就是对所有候选断言进行机器排序，过程和人工标注很相似。这里的机器排序算法是开源的LambdaMART算法。需要指出的是，这个方法思路很简单，但是做的比较精致的是特征工程，分别从word、phrase和sentence level抽取了特征进行组合。前两类特征比较简单，sentence level使用了CNN和GRU组合来抽取隐藏层的语义交互特征。下图同样来自PPT，其中包含一些和论文对不上的内容，最后是通过邮件和作者沟通后补充了部分，详情见批注。 实验 实验部分文章主要做了4个实验：分别测试生成法和抽取法的效果，以及很创新地分别把生成与抽取的结果再编码成特征放到Passage_based QA中去。后面两个实验是为了证明Assertion_based QA具有更多研究价值，可以辅助别的QA任务。 不过我感觉PPT有点“王婆卖瓜，自卖自夸”。我从文章中摘了一张针对后两个实验和其它算法一起比较效果的图放在下面，数据显示：1.工程性更重的抽取法效果好于生成法；2.CNN等方法得到的特征效果好于抽取法。 资料 译文和PPT 总结 总的来说，这篇论文确实做了非常多且较完整的开创性工作，特别是Assertion-based QA的定义和数据集，为QA领域开辟了一些新的思路。尽管提出的算法效果比较一般，但是也可以视作该领域的baseline之一，以鼓励更多更优秀的算法和模型出现。]]></content>
      <tags>
        <tag>QuestionAnswering</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Mining & NLP Internship in BaiFenDian Infotech]]></title>
    <url>%2F2018%2F03%2F20%2FData-Mining-NLP-Internship-in-BaiFenDian-Infotech%2F</url>
    <content type="text"><![CDATA[2017年10月-2018年3月，我在百分点自然语言处理组担任数据挖掘实习工程师 求职面试 其实面试真的很糟糕… 因为是第一份实习，而且当时真的是很弱的小白一只(现在也是= =)，所以面试几乎都没有答上来。 面试分成笔试、技术一面、技术二面和HR面。 笔试印象最深的是第一题，问有一个信号发射器，每次以不均等的概率发射0或1信号，如何组合出一个以均等概率发射0或1的信号发射器？如何组合出一个以均等概率发射0…N的信号发射器？然后…我很想当然地以为是像N次独立二项试验一样组合概率就可以，其实是要模拟二进制数。后面记不太清楚了，基本都是NLP编程题，读取文本之类的。还记得有一个算法题是要优化排序，然而我直接写用list.sort()不就好了…然后技术面就被问了list.sort()内部用的什么排序算法= =…最后就是一些机器学习的概念题，KNN和Kmeans概念之类的，比较简单。 技术面 一面基本上围绕笔试题，被疯狂吐槽了一番各种错误，基本上每道题都有错…后来坚定了我刷leetcode的决心… 二面问了一些实际开发的内容，先是介绍自己做过的SMP CUP 2017，再是问了诸如神经网络怎么防止过拟合等问题。说实话，这种沟通型面试我还是挺擅长的…各种嘴炮护体。 工作 工程方面：论坛帖子分类、检索式社区问答系统搭建 算法方面：利用N-gram和CNN实现相似句对判断、问答对质量评估，都是在问答系统搭建里面做的子模块 客户方面：一个远程电话支持，一个客户现场技术支持(我一个小小的实习生，怎么就跟着去做了售前呢…可能是我的嘴炮能力被发现了= =) 感想这个行业挣钱多不多？多。2017年可以说是中国的人工智能和机器学习元年。我们每天的数据中有80%是文本数据，所以以NLP为基础的数据处理业务增长迅速。大量的公司在分蛋糕，并且分得很轻松，俗称“降维打击”：大量的公司只是觉得人工智能高大上，实际上弱AI和机器学习很简单，各种工程用的都是github上的开源代码… 工作具体干什么？两类工作：业务线与产品线。业务指的是接销售、产品给的项目，然后做定制化开发；当然有的时候也包括售前支持，比如说去客户现场做技术支援。产品线指的是开发通用产品，比如说我一直负责开发的自动问答系统，甚至还包含了一点点算法研究的意味在里面。 能力要求怎么样？三个能力最重要：自己网上找资料的能力，熟练的代码能力和持续加班的身体能力。 要怎么培养能力？“偷看”公司以前的积累(来自前辈的教导~)多和同事聊天，勤问勤练；好记性不如烂笔头，把每天的事情都总结下来，调研+开发等多写代码，养成优秀的代码习惯：加注释+readme！！！想清楚自己的未来发展方向：工作？升学？但不管哪种，建议多读书..很多时候有啥不理解的，一看相关论文就有了思路。所以说我感觉这个领域读深一点真的没坏处，需要知识积累。 不足百分点以前一直是一个大数据工程公司，现在开始转型AI。正因如此，并且由于企业需要生存，它很多时候经营思路还是做工程，很少有沉下心来做算法研究的机会。我认为自己在工程上已经学到一点皮毛了，尽管很轻浮，但我还是希望能去一个研究型的AI公司感受一下算法研究工程师的工作∠( ᐛ 」∠)＿～]]></content>
      <tags>
        <tag>Internship</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SMP CUP 2017]]></title>
    <url>%2F2017%2F08%2F31%2FSMP-CUP-2017%2F</url>
    <content type="text"><![CDATA[SMP CUP 2017是我参加的第一个数据挖掘类比赛。 比赛简介给定CSDN用户的博客和行为数据（浏览、评论、收藏、转发、点赞/踩、关注、私信），进行用户画像生成。赛事官网地址：https://biendata.com/competition/smpcup2017/画像生成总共分为三项任务： 从给定博文中抽取3个关键词标签 从给定标签空间中选出3个来给给定用户打标签，依据是用户发表的博文以及一系列行为数据 通过给定用户过去一段时间的行为数据，预测其在未来一段时间内的成长值。用户成长值是根据用户的综合表现打分所得，但不知道具体打分准则。成长值将会归一化到[0, 1]区间，其中值为0表示用户流失。 数据样例 项目 内容 用户ID U00296783 博文ID D00034623 博文内容 Title:[转]使用TextRank算法为文本生成关键字和摘要; Content: TextRank算法基于PageRank… 博文标签 Keyword1: TextRank; Keyword2: PageRank; Keyword3: 摘要 用户标签 Tag1: 大数据; Tag2: 数据挖掘; Tag3: 机器学习 发布记录 U00296783／D00034623／20160408 12:35:49 浏览记录 D09983742／20160410 08:30:40 评论记录 D09983742／20160410 08:49:02 点赞记录 D00234899／20160410 09:40:24 点踩记录 D00098183／20160501 15:11:00 私信记录 U00296783／U02748273／20160501 15:30:36 收藏记录 D00234899／20160410 09:40:44 关注记录 U00296783／U02666623／20161119 10:30:44 成长打分 0.0367 (注：浏览、评论、点赞、点踩和收藏指的是该用户对其它博文的行为) 思路总结 抽取关键词其实方法也不太多，一开始想到的办法就是利用tfidf和textrank。后来查阅到了一些2016年搜狗CCF比赛的资料，就尝试把LDA抽取出来的主题关键词作为规则融合进来。简而言之，就是不断调整tfidf和textrank赋予给每个词的权重，尽可能地去提升比赛评分标准下的得分。 任务二大概的做法是先把用户行为分类转化成对应的文章，发表行为下的文章是一类，浏览的、评论的、点赞点踩的、收藏的文章是一类，私信和关注的用户所写的文章是一类。这个假设非常的主观，我们当时的依据就是用户做这些行为的成本不一样，比如说发表文章比较累…所以这些文章可以被分成3类，刚好对应3个标签(其实简单对训练集做了统计发现这个规律也确实还有一点点道理)。之后就是让每一类文章投票选出一个最可能的标签，分类方法是tfidf加权生成句向量+SVC。 成长值这个任务其实一看就是和时间序列有关的，但是局限于代码水平…当时就直接当作一个简单的回归问题来处理。先手动抽取了一些特征，比如每个用户过去每个月的评论数及增长率等，然后直接丢到PassiveAggressive和GrandientBoosting分类器里面，加一个Stacking做了融合预测。 模型实现 我在github上的开源代码 比赛心得 任务1：现在回过头来看这个方法真的非常稚嫩，但是倒也相当符合“规则派”的做法，毕竟我后来的实习工作中也证明了规则的有效性。不过第一名中科院团队的做法是纯正的神经网络，用来多个Softmax来投票，效果比第二名好了一大截，我怀疑除了他们大家都是tfidf+规则… 任务2：最开始采用了TextCNN的方法，但是效果比较一般，主要是不知道怎么把单标签分类的模型改成多标签…现在想想其实就是一个SoftMax…任务2我们的效果是最差的，我猜测就是因为主观假设太强了。 任务3：说实话这个模型的效果竟然意外的好，我觉得应该是因为纯数字数据的原因，毕竟对于数字，机器还是很容易去“拟合”一个模型出来的。 不过总的来说，当时真的是年轻头铁硬扛…开始比赛前，我连sklearn和numpy这些必备的包都不会用，更别说tensorflow和keras了。当时也是运气好，比赛因故延期了很长时间，我在比赛中期发现了kaggle和泰坦尼克数据集，并且由此自学了一堆机器学习的东西，才最后踉踉跄跄搞出了任务3的模型。像时间序列预测等等都没法做出来，很重要的原因是花了很长时间自学这些底层的东西，虽然按理来说应该在赛前就先打好基础的。不过回头看，此前整个实验组都没有经验，因为我们的辛苦帮老师和实验组做了一些开拓性的事情，还是非常让人喜悦的。]]></content>
      <tags>
        <tag>Data Mining Contest</tag>
      </tags>
  </entry>
</search>
